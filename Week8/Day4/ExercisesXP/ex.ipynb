{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 1: Calculating Required Sample Size\n",
    "You are planning an A/B test to evaluate the impact of a new email subject line on the open rate. Based on past data, you expect a small effect size of 0.3 (an increase from 20% to 23% in the open rate). You aim for an 80% chance (power = 0.8) of detecting this effect if it exists, with a 5% significance level (Î± = 0.05).  \n",
    "\n",
    "Calculate the required sample size per group using Pythonâ€™s statsmodels library.  \n",
    "What sample size is needed for each group to ensure your test is properly powered?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define sample size for the z-test because it is appropriate for large samples with known variances or proportion-based outcomes, typical in A/B testing scenarios involving binary outcomes (like open rates or click-through rates). The z-test assumes normality, which holds for large samples, making it suitable for common A/B testing situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174.41912242947043"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "\n",
    "# Define the parameters for the sample size calculation\n",
    "effect_size = 0.3  # Small effect size based on increase in open rate\n",
    "alpha = 0.05  # Significance level\n",
    "power = 0.8  # Power of the test\n",
    "\n",
    "\n",
    "# Calculate the sample size needed for each group\n",
    "sample_size_per_group = sms.zt_ind_solve_power(effect_size=effect_size, alpha=alpha, power=power, alternative='two-sided')\n",
    "\n",
    "sample_size_per_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size per group: 175.38\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "# Define the parameters\n",
    "effect_size = 0.3\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "\n",
    "# Calculate the sample size\n",
    "analysis = TTestIndPower()\n",
    "sample_size = analysis.solve_power(effect_size=effect_size, alpha=alpha, power=power)\n",
    "print(f'Required sample size per group: {sample_size:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 2: Understanding the Relationship Between Effect Size and Sample Size\n",
    "Using the same A/B test setup as in Exercise 1, you want to explore how changing the expected effect size impacts the required sample size.\n",
    "\n",
    "Calculate the required sample size for the following effect sizes: 0.2, 0.4, and 0.5, keeping the significance level and power the same.\n",
    "How does the sample size change as the effect size increases? Explain why this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Effect Size</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>392.443023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>98.110757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>62.790884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Effect Size  Sample Size\n",
       "0          0.2   392.443023\n",
       "1          0.4    98.110757\n",
       "2          0.5    62.790884"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the different effect sizes to evaluate\n",
    "effect_sizes = [0.2, 0.4, 0.5]\n",
    "\n",
    "# Calculate the required sample sizes for each effect size\n",
    "sample_sizes = [sms.zt_ind_solve_power(effect_size=es, alpha=alpha, power=power, alternative='two-sided') for es in effect_sizes]\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "sample_size_df = pd.DataFrame({\n",
    "    'Effect Size': effect_sizes,\n",
    "    'Sample Size': sample_sizes\n",
    "})\n",
    "\n",
    "sample_size_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 3: Exploring the Impact of Statistical Power\n",
    "Imagine you are conducting an A/B test where you expect a small effect size of 0.2. You initially plan for a power of 0.8 but wonder how increasing or decreasing the desired power level impacts the required sample size.\n",
    "\n",
    "Calculate the required sample size for power levels of 0.7, 0.8, and 0.9, keeping the effect size at 0.2 and significance level at 0.05.\n",
    "Question: How does the required sample size change with different levels of statistical power? Why is this understanding important when designing A/B tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Power Level</th>\n",
       "      <th>Sample Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>308.600198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>392.443023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>525.370971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Power Level  Sample Size\n",
       "0          0.7   308.600198\n",
       "1          0.8   392.443023\n",
       "2          0.9   525.370971"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the parameters for the sample size calculation\n",
    "effect_size = 0.2  # Small effect size\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "# Define the different power levels to evaluate\n",
    "power_levels = [0.7, 0.8, 0.9]\n",
    "\n",
    "# Calculate the required sample sizes for each power level\n",
    "sample_sizes_power = [sms.zt_ind_solve_power(effect_size=effect_size, alpha=alpha, power=power, alternative='two-sided') for power in power_levels]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "sample_size_power_df = pd.DataFrame({\n",
    "    'Power Level': power_levels,\n",
    "    'Sample Size': sample_sizes_power\n",
    "})\n",
    "\n",
    "sample_size_power_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 4: Implementing Sequential Testing\n",
    "You are running an A/B test on two versions of a product page to increase the purchase rate. You plan to monitor the results weekly and stop the test early if one version shows a significant improvement.  \n",
    "\n",
    "Define your stopping criteria.  \n",
    "Decide how you would implement sequential testing in this scenario.  \n",
    "At the end of week three, Version B has a p-value of 0.02. What would you do next?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Stopping Criteria**: Set a pre-defined adjusted significance level for each interim check (e.g., alpha_adjusted = 0.015) using methods like Pocock boundaries.\n",
    "\n",
    "2. **Sequential Testing Implementation**: Conduct weekly analyses, adjust the p-value threshold for each check, and stop the test if the p-value falls below the threshold.\n",
    "\n",
    "3. **Next Step at Week Three (p = 0.02)**: Since the p-value (0.02) is higher than the adjusted threshold (0.015), continue the test and check again next week.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 5: Applying Bayesian A/B Testing\n",
    "Youâ€™re testing a new feature in your app, and you want to use a Bayesian approach. Initially, you believe the new feature has a 50% chance of improving user engagement. After collecting data, your analysis suggests a 65% probability that the new feature is better.\n",
    "\n",
    "Describe how you would set up your prior belief.  \n",
    "After collecting data, how does the updated belief (posterior distribution) influence your decision?  \n",
    "What would you do if the posterior probability was only 55%?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Prior Belief Setup**: Start with a neutral prior belief, assuming a 50% chance the new feature improves user engagement.\n",
    "\n",
    "2. **Updated Belief (Posterior)**: After data collection, the posterior (65% probability) increases confidence that the feature is better, guiding you to potentially roll out the feature.\n",
    "\n",
    "3. **If Posterior is 55%**: With only a 55% probability, the evidence is weak, so you might continue gathering more data before making a decision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 6: Implementing Adaptive Experimentation\n",
    "Youâ€™re running a test with three different website layouts to increase user engagement. Initially, each layout gets 33% of the traffic. After the first week, Layout C shows higher engagement.\n",
    "\n",
    "Explain how you would adjust the traffic allocation after the first week.  \n",
    "Describe how you would continue to adapt the experiment in the following weeks.  \n",
    "What challenges might you face with adaptive experimentation, and how would you address them?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Traffic Adjustment**: After the first week, allocate more traffic to Layout C while reducing traffic to the other layouts.\n",
    "\n",
    "2. **Ongoing Adaptation**: Continue adjusting traffic weekly, sending more traffic to layouts with higher engagement and less to lower-performing ones.\n",
    "\n",
    "3. **Challenges**: You might face issues like **early overfitting** or **insufficient data for underperforming layouts**; address them by maintaining a **minimum traffic allocation** to all layouts for accurate comparison.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JUPYTER_DEFAULT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
