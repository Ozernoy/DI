{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392.4430232577885,\n",
       "    Effect Size  Sample Size\n",
       " 0          0.1  1569.772102\n",
       " 1          0.2   392.443023\n",
       " 2          0.3   174.419122\n",
       " 3          0.4    98.110757)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.stats.api as sms\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters for the A/B test\n",
    "conversion_rate_current = 0.05  # Current conversion rate\n",
    "conversion_rate_new = 0.07  # Expected conversion rate with the new checkout process\n",
    "effect_size = 0.2  # Given effect size for initial sample size calculation\n",
    "alpha = 0.05  # Significance level\n",
    "power = 0.8  # Desired power level\n",
    "\n",
    "# Calculate the required sample size for the given effect size\n",
    "sample_size_initial = sms.zt_ind_solve_power(effect_size=effect_size, alpha=alpha, power=power, alternative='two-sided')\n",
    "\n",
    "# Analyze the impact of different effect sizes on required sample size\n",
    "effect_sizes = [0.1, 0.2, 0.3, 0.4]\n",
    "sample_sizes = [sms.zt_ind_solve_power(effect_size=es, alpha=alpha, power=power, alternative='two-sided') for es in effect_sizes]\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "sample_size_df = pd.DataFrame({\n",
    "    'Effect Size': effect_sizes,\n",
    "    'Sample Size': sample_sizes\n",
    "})\n",
    "\n",
    "# Display the initial sample size and the effect size analysis\n",
    "sample_size_initial, sample_size_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether the new checkout process (with an expected conversion rate of 7%) outperforms the current one (with a 5% conversion rate), the required sample size for each group, with an effect size of 0.2, is approximately 392 participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smaller the effect size, the larger the sample needed to detect a difference. This is because small changes (like improving conversion rate by a tiny margin) are harder to spot and require more data to confirm. On the other hand, larger effects are more noticeable, so fewer samples are needed to be confident. In A/B testing, balancing effect size and sample size ensures you're not wasting resources (too many participants) or missing important insights (too few participants), helping you confidently make decisions to boost your bakery's sweet sales!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JUPYTER_DEFAULT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
